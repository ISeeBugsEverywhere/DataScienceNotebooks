{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b2b_gv_vartojimas.xlsx', 'b2b_ngv_vartojimas.xlsx', 'b2c_gv_vartojimas.xlsx', 'b2c_ngv_vartojimas.xlsx', 'REGRESIJOS.pdf', 'Uzduotis.txt']\n",
      "75 paskaita. Pasiruošta 2025-01-08 19:53:31\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_dir=\"../../../duomenys/elektros_paklausa/\"; # print(listdir(csv_dir))\n",
    "data_files=['b2b_gv_vartojimas.xlsx', 'b2c_gv_vartojimas.xlsx', 'b2c_ngv_vartojimas.xlsx', 'b2b_ngv_vartojimas.xlsx']\n",
    "date_cols=['data_valanda', 'dateTime', 'dateTime', 'data_valanda']\n",
    "\n",
    "print(listdir(data_dir))\n",
    "\n",
    "print('75 paskaita. Pasiruošta',dt.now().replace(microsecond=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../duomenys/elektros_paklausa/b2b_gv_vartojimas.xlsx\n",
      "         data_valanda    0    1     2      3    4    5       6       7  \\\n",
      "0 2022-11-01 00:00:00  0.0  0.0  4.68  0.001  0.0  0.0  1.7159  1.9334   \n",
      "1 2022-11-01 01:00:00  0.0  0.0  4.34  0.001  0.0  0.0  1.0673  0.5732   \n",
      "2 2022-11-01 02:00:00  0.0  0.0  4.12  0.000  0.0  0.0  1.3911  1.1709   \n",
      "\n",
      "        8  ...  753     754    755  756  757     758   759     760     761  \\\n",
      "0  1.4671  ...  5.0  0.4199  23.40  0.0  0.0  5.9883  91.9  0.3135  6.9318   \n",
      "1  1.1481  ...  4.7  0.3783  22.44  0.0  0.0  5.2497  90.5  0.2949  5.3964   \n",
      "2  4.9880  ...  4.7  0.3251  22.26  0.0  0.0  4.7670  94.7  0.1766  5.3742   \n",
      "\n",
      "      762  \n",
      "0  2.8310  \n",
      "1  2.8309  \n",
      "2  2.8025  \n",
      "\n",
      "[3 rows x 764 columns]\n",
      "../../../duomenys/elektros_paklausa/b2c_gv_vartojimas.xlsx\n",
      "             dateTime      0      1      2      3      4      5      6      7  \\\n",
      "0 2023-08-01 00:00:00  1.128  0.301  0.078  0.083  0.306  0.239  0.666  1.050   \n",
      "1 2023-08-01 01:00:00  1.465  0.262  0.095  0.090  0.303  0.214  0.696  0.467   \n",
      "2 2023-08-01 02:00:00  0.790  0.354  0.265  0.101  0.311  0.636  0.692  0.158   \n",
      "\n",
      "       8  ...  1040  1041  1042  1043  1044  1045  1046  1047  1048  1049  \n",
      "0  0.284  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1  0.263  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2  0.276  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[3 rows x 1051 columns]\n",
      "../../../duomenys/elektros_paklausa/b2c_ngv_vartojimas.xlsx\n",
      "             dateTime      0      1      2      3      4      5      6      7  \\\n",
      "0 2023-08-01 00:00:00  0.117  0.103  0.041  0.070  0.126  0.048  0.131  0.171   \n",
      "1 2023-08-01 01:00:00  0.501  0.043  0.046  0.120  0.104  0.051  0.110  0.210   \n",
      "2 2023-08-01 02:00:00  0.185  0.052  0.046  0.145  0.066  0.047  0.110  0.195   \n",
      "\n",
      "       8  ...  1016  1017  1018  1019  1020  1021  1022  1023  1024  1025  \n",
      "0  0.347  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1  0.963  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2  0.574  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[3 rows x 1027 columns]\n",
      "../../../duomenys/elektros_paklausa/b2b_ngv_vartojimas.xlsx\n",
      "         data_valanda    0  1      2      3    4    5      6      7    8  ...  \\\n",
      "0 2022-11-01 00:00:00  0.0  0  0.014  0.018  0.0  0.0  0.014  0.049  0.0  ...   \n",
      "1 2022-11-01 01:00:00  0.0  0  0.013  0.018  0.0  0.0  0.013  0.048  0.0  ...   \n",
      "2 2022-11-01 02:00:00  0.0  0  0.014  0.017  0.0  0.0  0.015  0.048  0.0  ...   \n",
      "\n",
      "     789    790  791  792  793  794  795    796  797    798  \n",
      "0  0.034  0.335  0.0  0.0  0.0  0.0  0.0  0.071  0.0  0.459  \n",
      "1  0.033  0.335  0.0  0.0  0.0  0.0  0.0  0.039  0.0  0.437  \n",
      "2  0.035  0.346  0.0  0.0  0.0  0.0  0.0  0.083  0.0  0.457  \n",
      "\n",
      "[3 rows x 800 columns]\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "df_list = []\n",
    "\n",
    "# for index, file in enumerate(data_files):\n",
    "    \n",
    "for file in data_files:\n",
    "    print(f'{csv_dir}{file}')\n",
    "    day_df = pd.read_excel(f'{data_dir}{file}')\n",
    "    # day_df['datetime'] = pd.to_datetime(day_df[[date_cols[index]]])\n",
    "    # day_df['hour'] = day_df['datetime'].dt.hour\n",
    "    # day_df['cos_hour'] = np.cos(2 * np.pi * day_df['hour'] % 24 / 24)\n",
    "    \n",
    "    df_list.append(day_df)\n",
    "    # day_df = day_df[['hour', 'cos_hour', 'air_temperature']]  # Pasirenkame reikiamus stulpelius\n",
    "    # final_df = pd.concat([final_df, day_df], ignore_index=True)\n",
    "    \n",
    "    print(day_df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1     2      3    4    5       6       7       8      9  ...   755  \\\n",
      "0  0.0  0.0  4.68  0.001  0.0  0.0  1.7159  1.9334  1.4671  0.986  ...  23.4   \n",
      "\n",
      "   756  757     758   759     760     761    762   datetime  hour  \n",
      "0  0.0  0.0  5.9883  91.9  0.3135  6.9318  2.831 2022-11-01     0  \n",
      "\n",
      "[1 rows x 765 columns]\n",
      "       0      1      2      3      4      5      6     7      8      9  ...  \\\n",
      "0  1.128  0.301  0.078  0.083  0.306  0.239  0.666  1.05  0.284  1.455  ...   \n",
      "\n",
      "   1042  1043  1044  1045  1046  1047  1048  1049   datetime  hour  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 2023-08-01     0  \n",
      "\n",
      "[1 rows x 1052 columns]\n",
      "       0      1      2     3      4      5      6      7      8      9  ...  \\\n",
      "0  0.117  0.103  0.041  0.07  0.126  0.048  0.131  0.171  0.347  0.185  ...   \n",
      "\n",
      "   1018  1019  1020  1021  1022  1023  1024  1025   datetime  hour  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0 2023-08-01     0  \n",
      "\n",
      "[1 rows x 1028 columns]\n",
      "     0  1      2      3    4    5      6      7    8      9  ...  791  792  \\\n",
      "0  0.0  0  0.014  0.018  0.0  0.0  0.014  0.049  0.0  2.429  ...  0.0  0.0   \n",
      "\n",
      "   793  794  795    796  797    798   datetime  hour  \n",
      "0  0.0  0.0  0.0  0.071  0.0  0.459 2022-11-01     0  \n",
      "\n",
      "[1 rows x 801 columns]\n"
     ]
    }
   ],
   "source": [
    "for index, df in enumerate(df_list):\n",
    "    # print(date_cols[index])\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df[date_cols[index]])\n",
    "    del df[date_cols[index]]\n",
    "\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    # df['cos_hour'] = np.cos(2 * np.pi * df['hour'] % 24 / 24)\n",
    "    \n",
    "    print(df.head(1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Išvedame pirmąsias ir paskutininiasias eilutes.\n",
      "Tai padės pasirinkti datų ijtervalą tolesniame žingsnyje.\n",
      "\n",
      "0   2022-11-01 00:00:00\n",
      "1   2022-11-01 01:00:00\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "8758   2023-10-31 23:00:00\n",
      "8759   2023-11-01 00:00:00\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "\n",
      "0   2023-08-01 00:00:00\n",
      "1   2023-08-01 01:00:00\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "2183   2023-10-30 23:00:00\n",
      "2184   2023-10-31 00:00:00\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "\n",
      "0   2023-08-01 00:00:00\n",
      "1   2023-08-01 01:00:00\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "2183   2023-10-30 23:00:00\n",
      "2184   2023-10-31 00:00:00\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "\n",
      "0   2022-11-01 00:00:00\n",
      "1   2022-11-01 01:00:00\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "8758   2023-10-31 23:00:00\n",
      "8759   2023-11-01 00:00:00\n",
      "Name: datetime, dtype: datetime64[ns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Išvedame pirmąsias ir paskutininiasias eilutes.')\n",
    "print('Tai padės pasirinkti datų ijtervalą tolesniame žingsnyje.')\n",
    "print()\n",
    "\n",
    "for df in df_list:\n",
    "    print(df['datetime'].head(2))\n",
    "    print(df['datetime'].tail(2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stulperlių sumos statistinė suvestinė\n",
      "count     8712.000000\n",
      "mean      8950.359862\n",
      "std       3562.098289\n",
      "min        713.618500\n",
      "25%       6721.939987\n",
      "50%       8064.628053\n",
      "75%      10268.757057\n",
      "max      20983.552814\n",
      "Name: sum, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Apmokymui naudosime šio intervalo duomenis:\n",
    "start_date = '2022-10-30'\n",
    "end_date = '2023-10-30'\n",
    "\n",
    "# Atrenkame iš nurodyto datos intervalo:\n",
    "filtered_dfs = []\n",
    "for index, df in enumerate(df_list):\n",
    "    \n",
    "    # Visus kaičius ir str verčiu pd.to_numeric.\n",
    "    df.loc[:, df.select_dtypes(include=['number', 'object']).columns] = df.select_dtypes(include=['number', 'object']).apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    filtered_dfs.append(df[( start_date <= df['datetime'] )&( df['datetime'] <= end_date )])\n",
    "\n",
    "# Apjungiame pagal 'datetime' stulpelį\n",
    "result = pd.concat(filtered_dfs, axis=1)\n",
    "\n",
    "# Pašaliname pasikartojančius 'datetime' stulpelius\n",
    "result = result.loc[:, ~result.columns.duplicated()]\n",
    "\n",
    "result = result.dropna(axis=1, how='all')\n",
    "\n",
    "result['sum'] = result.select_dtypes(include='number').sum(axis=1)\n",
    "\n",
    "print('Stulperlių sumos statistinė suvestinė')\n",
    "print(result['sum'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       5207.003717\n",
      "1       5047.433892\n",
      "2       5066.476851\n",
      "3       5018.805316\n",
      "4       4999.327525\n",
      "           ...     \n",
      "8707    8030.312198\n",
      "8708    7656.830533\n",
      "8709    7339.802166\n",
      "8710    7186.392000\n",
      "8711    6894.730016\n",
      "Name: sum, Length: 8712, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(result['sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeliuojame\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Tiesinės regresijos modelis\u001b[39;00m\n\u001b[0;32m     15\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Prognozės ir modelio tikslumo įvertinimas\u001b[39;00m\n\u001b[0;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\linear_model\\_base.py:601\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    597\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    599\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 601\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    611\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2919\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_data\u001b[39m(\n\u001b[0;32m   2836\u001b[0m     _estimator,\n\u001b[0;32m   2837\u001b[0m     \u001b[38;5;241m/\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2843\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m   2844\u001b[0m ):\n\u001b[0;32m   2845\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[0;32m   2846\u001b[0m \n\u001b[0;32m   2847\u001b[0m \u001b[38;5;124;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m   2918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2919\u001b[0m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2920\u001b[0m     tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[0;32m   2921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2715\u001b[0m, in \u001b[0;36m_check_feature_names\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2688\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set or check the `feature_names_in_` attribute of an estimator.\u001b[39;00m\n\u001b[0;32m   2689\u001b[0m \n\u001b[0;32m   2690\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2711\u001b[0m \u001b[38;5;124;03m       should set `reset=False`.\u001b[39;00m\n\u001b[0;32m   2712\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[1;32m-> 2715\u001b[0m     feature_names_in \u001b[38;5;241m=\u001b[39m \u001b[43m_get_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2717\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m feature_names_in\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\validation.py:2417\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m   2415\u001b[0m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[0;32m   2416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[1;32m-> 2417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names are only supported if all input features have string names, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2419\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as feature name / column name types. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2420\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2423\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata, or convert them all to a non-string data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2424\u001b[0m     )\n\u001b[0;32m   2426\u001b[0m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[0;32m   2427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "print('Modeliuojame')\n",
    "# pip install scikit-learn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = result.drop(columns=['sum','datetime'])  # Nepriklausomi kintamieji\n",
    "y = result['sum']  # Priklausomasis kintamasis\n",
    "\n",
    "# Duomenų padalijimas į treniravimo ir testavimo rinkinius\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=11)\n",
    "\n",
    "# Tiesinės regresijos modelis\n",
    "model = LinearRegression()\n",
    "model.fit( X_train, y_train )\n",
    "\n",
    "# Prognozės ir modelio tikslumo įvertinimas\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "       ...\n",
       "       1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049],\n",
       "      dtype='object', length=1051)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5696     9120.300727\n",
       "1104     8089.405451\n",
       "2898    12599.957250\n",
       "2321     9064.221266\n",
       "4061     9952.361172\n",
       "            ...     \n",
       "1293     6761.013542\n",
       "4023     9774.293050\n",
       "7259     9746.908818\n",
       "5200     5780.424278\n",
       "3775    14042.917419\n",
       "Name: sum, Length: 7840, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Užrašai:\n",
    "# Multi-target regression\n",
    "# https://stackoverflow.com/questions/57704609/multi-target-regression-using-scikit-learn\n",
    "# https://medium.com/@tubelwj/developing-multi-class-regression-models-with-python-c8beca5dd482"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
