{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, pacf\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Įkelia elektros suvartojimo duomenis.\"\"\"\n",
    "    df: pd.DataFrame = pd.read_csv(file_path, parse_dates=['Date'], index_col='Date')\n",
    "    return df\n",
    "\n",
    "def check_stationarity(series: pd.Series) -> Tuple[bool, float]:\n",
    "    \"\"\"Tikrina, ar laiko eilutė yra stacionari naudojant ADF testą.\"\"\"\n",
    "    result = adfuller(series)\n",
    "    p_value: float = result[1]\n",
    "    return p_value < 0.05, p_value  # True, jei stacionari\n",
    "\n",
    "def plot_acf_pacf(series: pd.Series) -> None:\n",
    "    \"\"\"Nubraižo autokoreliacijos ir dalinės autokoreliacijos grafikus.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    sm.graphics.tsa.plot_acf(series, lags=20, ax=axes[0])\n",
    "    sm.graphics.tsa.plot_pacf(series, lags=20, ax=axes[1])\n",
    "    axes[0].set_title(\"Autokoreliacijos funkcija (ACF)\")\n",
    "    axes[1].set_title(\"Dalinės autokoreliacijos funkcija (PACF)\")\n",
    "    plt.show()\n",
    "\n",
    "def train_ar_model(series: pd.Series, lag: int) -> AutoReg:\n",
    "    \"\"\"Treniruoja autoregresinį (AR) modelį.\"\"\"\n",
    "    model = AutoReg(series, lags=lag).fit()\n",
    "    return model\n",
    "\n",
    "def forecast_ar(model: AutoReg, steps: int) -> np.ndarray:\n",
    "    \"\"\"Atlieka ateities reikšmių prognozę naudojant AR modelį.\"\"\"\n",
    "    predictions: np.ndarray = model.predict(start=len(model.model.endog), end=len(model.model.endog) + steps - 1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PAGRINDINĖ PROGRAMOS DALIS ===\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Duomenų įkėlimas\n",
    "    file_path: str = \"electricity_data.csv\"  # Nurodykite teisingą failo pavadinimą\n",
    "    data: pd.DataFrame = load_data(file_path)\n",
    "    \n",
    "    # 2. Tikriname stacionarumą\n",
    "    is_stationary, p_value = check_stationarity(data['KWH_mean'])\n",
    "    print(f\"Stacionarumas: {is_stationary}, p-reikšmė: {p_value:.5f}\")\n",
    "    \n",
    "    # 3. Jei reikia, diferencijuojame duomenis\n",
    "    if not is_stationary:\n",
    "        data['KWH_mean'] = data['KWH_mean'].diff().dropna()\n",
    "    \n",
    "    # 4. Parodome ACF ir PACF grafikus\n",
    "    plot_acf_pacf(data['KWH_mean'].dropna())\n",
    "    \n",
    "    # 5. Treniravimas (naudojame PACF rezultatą pasirinkti lag reikšmę)\n",
    "    lag: int = 3  # Galima keisti pagal PACF analizę\n",
    "    ar_model: AutoReg = train_ar_model(data['KWH_mean'].dropna(), lag)\n",
    "    \n",
    "    # 6. Prognozė\n",
    "    steps: int = 12  # Prognozuojame 12 mėnesių į priekį\n",
    "    forecast_values: np.ndarray = forecast_ar(ar_model, steps)\n",
    "    \n",
    "    # 7. Rezultatų vizualizacija\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data.index, data['KWH_mean'], label='Istoriniai duomenys')\n",
    "    plt.plot(pd.date_range(start=data.index[-1], periods=steps, freq='M'), forecast_values, label='Prognozė', linestyle='dashed')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Laikas\")\n",
    "    plt.ylabel(\"KWH_mean\")\n",
    "    plt.title(\"Autoregresijos modelio prognozė\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer():\n",
    "  def __init__(self):\n",
    "  self.DF_DATA = None\n",
    " \n",
    "  def fit(self, data, X_features:list, y_target:str):\n",
    "    self.DF_DATA = data[X_features+[y_target]].groupby(X_features).mean().reset_index()\n",
    "    pass\n",
    " \n",
    "  def predict(self, d:str):\n",
    "   dt = pd.to_datetime(d)\n",
    "   M = dt.month\n",
    "   D = dt.day_of_week\n",
    "   h24 = self.DF_DATA.query(expr='MM == @M and DD == @D')\n",
    "   return h24[['HH', 'value']]\n",
    "\n",
    "# [['MM','DD', 'HH', 'value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita užduotis:\n",
    "https://github.com/Call-for-Code/Spot-Challenge-Wildfires/blob/main/data/Readme_Docs_Wildfires-Datasets_2020-11.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
